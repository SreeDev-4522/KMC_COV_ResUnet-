{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SreeDev-4522/KMC_COV_ResUnet-/blob/main/ResUnet_KMC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1CdrgTuw7bN"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# src = list(files.upload().values())[0]\n",
        "# open('ss_utils.py','wb').write(src)\n",
        "# import ss_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0WQWXKkCjak",
        "outputId": "679eefed-640b-4047-ee16-7eea942498e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUUdDillySB6",
        "outputId": "5f6b4ad2-5566-4d0d-ac28-9ec0343e7a13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.47.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.17.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.7/dist-packages (0.3.14)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.7/dist-packages (0.3.14+cuda11.cudnn805)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.7/dist-packages (from jax) (1.7.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jax) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.7/dist-packages (from jax) (1.21.6)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from jax) (0.6.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib) (2.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax) (5.8.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax) (3.8.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install tensorflow_addons\n",
        "!pip install --upgrade jax jaxlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XIxNZib5cFJ"
      },
      "source": [
        "data.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65KIXWlj5Y7v"
      },
      "outputs": [],
      "source": [
        "import os,cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import glob\n",
        "\n",
        "class1 = [0,160,255] #blue\n",
        "class2 = [255,255,128] #yellow\n",
        "class3 = [255,0,0] #red\n",
        "class0 = [0,0,0] #background which is the final class\n",
        "\n",
        "check_path = os.path.dirname(os.getcwd()) + \"/Results/check\"\n",
        "label_values = [class1] + [class2] + [class3] + [class0]\n",
        "num_classes = len(label_values)\n",
        "\n",
        "def one_hot(mask):\n",
        "    semantic_map = []\n",
        "    for colour in label_values:\n",
        "        equality = np.equal(mask, colour)\n",
        "        class_map = np.all(equality, axis = -1)\n",
        "        semantic_map.append(class_map)\n",
        "    semantic_map = (np.stack(semantic_map, axis=-1)).astype(float)\n",
        "    return semantic_map\n",
        "\n",
        "def adjustData(img,mask):\n",
        "    img = img / 255\n",
        "    mask = one_hot(mask)\n",
        "    return (img,mask)\n",
        "\n",
        "def dataGenerator(batch_size,path,aug_dict,size,seed=1):\n",
        "    image_datagen = ImageDataGenerator(**aug_dict)\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        path,\n",
        "        target_size=(size, size),\n",
        "        classes = [\"images\"],\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "       save_to_dir = \"/content/drive/MyDrive/KMC/Check/Image\",\n",
        "       save_prefix = 'image',\n",
        "        seed = seed)\n",
        "    mask_generator = image_datagen.flow_from_directory(\n",
        "        path,\n",
        "        target_size=(size, size),\n",
        "        classes = [\"mask\"],\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "       save_to_dir = \"/content/drive/MyDrive/KMC/Check/Mask\",\n",
        "       save_prefix= 'mask',\n",
        "        seed = seed)\n",
        "    data_generator = zip(image_generator, mask_generator)\n",
        "    for (image,mask) in data_generator:\n",
        "        image,mask = adjustData(image,mask)\n",
        "        yield (image,mask)\n",
        "        \n",
        "def valGenerator(batch_size,path,size,seed=1):\n",
        "    image_datagen = ImageDataGenerator()\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        path,\n",
        "        target_size=(size, size),\n",
        "        classes = [\"images\"],\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    mask_generator = image_datagen.flow_from_directory(\n",
        "        path,\n",
        "        target_size=(size, size),\n",
        "        classes = [\"mask\"],\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    data_generator = zip(image_generator, mask_generator)\n",
        "    for (image,mask) in data_generator:\n",
        "        image,mask = adjustData(image,mask)\n",
        "        yield (image,mask)        \n",
        "\n",
        "def dataGenerator2(batch_size,path,aug_dict,seed=1):\n",
        "    image_datagen = ImageDataGenerator(**aug_dict)\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        path,\n",
        "        target_size=(size, size),\n",
        "        classes = [\"images\"],\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    mask_generator = image_datagen.flow_from_directory(\n",
        "        path,\n",
        "        target_size=(size, size),\n",
        "        classes = [\"mask\"],\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    image2_generator = image_datagen.flow_from_directory(\n",
        "        path,\n",
        "        target_size=(size, size),\n",
        "        classes = [\"ul_val_images\"],\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    mask2_generator = image_datagen.flow_from_directory(\n",
        "        path,\n",
        "        target_size=(size, size),\n",
        "        classes = [\"ul_val_mask\"],\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    data_generator = zip(image_generator, mask_generator,image2_generator, mask2_generator)\n",
        "    for (image,mask,image2,mask2) in data_generator:\n",
        "        image,mask = adjustData(image,mask)\n",
        "        image2,mask2 = adjustData(image2,mask2)\n",
        "        yield [[image,image2],[mask,mask2]]\n",
        "\n",
        "def dataGenerator3(batch_size,path1,path2,aug_dict,size,size2,k=2,T=0.5,seed=1):\n",
        "    image_datagen = ImageDataGenerator(**aug_dict)\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        path1,\n",
        "        target_size=(size, size),\n",
        "        classes = [\"images\"],\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    mask_generator = image_datagen.flow_from_directory(\n",
        "        path1,\n",
        "        target_size=(size, size),\n",
        "        classes = [\"mask\"],\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    image2_generator = image_datagen.flow_from_directory(\n",
        "        path2,\n",
        "        target_size=(size2, size2),\n",
        "        classes = [\"images\"],\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    data_generator = zip(image_generator, mask_generator,image2_generator)\n",
        "    for (image,mask,image2) in data_generator:\n",
        "        image,mask = adjustData(image,mask)\n",
        "        image2/=255\n",
        "        mask2 = np.repeat(mask,k,axis=0)\n",
        "        train = ([image,image2],[mask,mask2])\n",
        "        yield train\n",
        "        \n",
        "\n",
        "def dataGenerator4(batch_size,path1,path2,aug_dict,size,size2,k=2,T=0.5,seed=1):\n",
        "    image_datagen = ImageDataGenerator(**aug_dict)\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        path1,\n",
        "        target_size=(size, size),\n",
        "        classes = [\"images\"],\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    mask_generator = image_datagen.flow_from_directory(\n",
        "        path1,\n",
        "        target_size=(size, size),\n",
        "        classes = [\"mask\"],\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    image2_generator = image_datagen.flow_from_directory(\n",
        "        path2,\n",
        "        target_size=(size2, size2),\n",
        "        classes = [\"images\"],\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    data_generator = zip(image_generator, mask_generator,image2_generator)\n",
        "    for (image,mask,image2) in data_generator:\n",
        "        image,mask = adjustData(image,mask)\n",
        "        image2/=255\n",
        "        mask2 = np.repeat(mask,k,axis=0)\n",
        "        mask = np.concatenate((mask,mask2),axis=0)\n",
        "        m,n,o,p=mask.shape\n",
        "        mask = np.reshape(mask,(m,n*o,p))\n",
        "        mask = mask[np.newaxis,:]\n",
        "        train = ([image,image2],mask)\n",
        "        yield train\n",
        "def dataGenerator5(batch_size,path1,path2,aug_dict,size,size2,k=2,T=0.5,seed=1):\n",
        "    image_datagen = ImageDataGenerator(**aug_dict)\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        path1,\n",
        "        target_size=(size2, size2),\n",
        "        classes = [\"images_padded\"],\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    mask_generator = image_datagen.flow_from_directory(\n",
        "        path1,\n",
        "        target_size=(size, size),\n",
        "        classes = [\"mask\"],\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    image2_generator = image_datagen.flow_from_directory(\n",
        "        path2,\n",
        "        target_size=(size2, size2),\n",
        "        classes = [\"images_padded\"],\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    data_generator = zip(image_generator, mask_generator,image2_generator)\n",
        "    for (image,mask,image2) in data_generator:\n",
        "        image,mask = adjustData(image,mask)\n",
        "        image2/=255\n",
        "        mask2 = np.repeat(mask,k,axis=0)\n",
        "        mask = np.concatenate((mask,mask2),axis=0)\n",
        "        m,n,o,p=mask.shape\n",
        "        mask = np.reshape(mask,(m,n*o,p))\n",
        "        mask = mask[np.newaxis,:]\n",
        "        train = ([image,image2],mask)\n",
        "        yield train \n",
        "   \n",
        "                    \n",
        "def valGenerator3(batch_size,path1,path2,size,size2,k=2,T=0.5,seed=1):\n",
        "    image_datagen = ImageDataGenerator()\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        path1,\n",
        "        target_size=(size, size),\n",
        "        classes = [\"images\"],\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    mask_generator = image_datagen.flow_from_directory(\n",
        "        path1,\n",
        "        target_size=(size, size),\n",
        "        classes = [\"mask\"],\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    image2_generator = image_datagen.flow_from_directory(\n",
        "        path2,\n",
        "        target_size=(size2, size2),\n",
        "        classes = [\"images\"],\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    mask2_generator = image_datagen.flow_from_directory(\n",
        "        path1,\n",
        "        target_size=(size2, size2),\n",
        "        classes = [\"mask\"],\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)        \n",
        "    data_generator = zip(image_generator, mask_generator,image2_generator, mask2_generator)\n",
        "    for (image,mask,image2,mask2) in data_generator:\n",
        "        image,mask = adjustData(image,mask)\n",
        "        image2,mask2 = adjustData(image2,mask2)\n",
        "        mask2 = np.repeat(mask2,k,axis=0)\n",
        "        train = ([image,image2],{'augm_layer_1':mask,'augm_layer_3':mask2})\n",
        "        yield train\n",
        "        \n",
        "def valGenerator4(batch_size,path1,path2,size,size2,k=2,T=0.5,seed=1):\n",
        "    image_datagen = ImageDataGenerator()\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        path1,\n",
        "        target_size=(size, size),\n",
        "        classes = [\"images\"],\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    mask_generator = image_datagen.flow_from_directory(\n",
        "        path1,\n",
        "        target_size=(size, size),\n",
        "        classes = [\"mask\"],\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    image2_generator = image_datagen.flow_from_directory(\n",
        "        path2,\n",
        "        target_size=(size2, size2),\n",
        "        classes = [\"images\"],\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    mask2_generator = image_datagen.flow_from_directory(\n",
        "        path1,\n",
        "        target_size=(size, size),\n",
        "        classes = [\"mask\"],\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)        \n",
        "    data_generator = zip(image_generator, mask_generator,image2_generator, mask2_generator)\n",
        "    for (image,mask,image2,mask2) in data_generator:\n",
        "        image,mask = adjustData(image,mask)\n",
        "        image2,mask2 = adjustData(image2,mask2)\n",
        "        mask2 = np.repeat(mask2,k,axis=0)\n",
        "        mask = np.concatenate((mask,mask2),axis=0)\n",
        "        m,n,o,p=mask.shape\n",
        "        mask = np.reshape(mask,(m,n*o,p))\n",
        "        mask = mask[np.newaxis,:]\n",
        "        train = ([image,image2],mask)\n",
        "        yield train\n",
        "\n",
        "def valGenerator5(batch_size,path1,path2,size,size2,k=2,T=0.5,seed=1):\n",
        "    image_datagen = ImageDataGenerator()\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        path1,\n",
        "        target_size=(size2, size2),\n",
        "        classes = [\"images_padded\"],\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    mask_generator = image_datagen.flow_from_directory(\n",
        "        path1,\n",
        "        target_size=(size, size),\n",
        "        classes = [\"mask\"],\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    image2_generator = image_datagen.flow_from_directory(\n",
        "        path2,\n",
        "        target_size=(size2, size2),\n",
        "        classes = [\"images_padded\"],\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    mask2_generator = image_datagen.flow_from_directory(\n",
        "        path1,\n",
        "        target_size=(size, size),\n",
        "        classes = [\"mask\"],\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)        \n",
        "    data_generator = zip(image_generator, mask_generator,image2_generator, mask2_generator)\n",
        "    for (image,mask,image2,mask2) in data_generator:\n",
        "        image,mask = adjustData(image,mask)\n",
        "        image2,mask2 = adjustData(image2,mask2)\n",
        "        mask2 = np.repeat(mask2,k,axis=0)\n",
        "        mask = np.concatenate((mask,mask2),axis=0)\n",
        "        m,n,o,p=mask.shape\n",
        "        mask = np.reshape(mask,(m,n*o,p))\n",
        "        mask = mask[np.newaxis,:]\n",
        "        train = ([image,image2],mask)\n",
        "        yield train\n",
        "        \n",
        "\n",
        "        \n",
        "def sharpen1(p, T):\n",
        "    return np.power(p, 1/T) / np.mean(np.power(p, 1/T), axis=-1, keepdims=True)\n",
        "    \n",
        "def sharpen(p, T):\n",
        "    return tf.pow(p, 1/T) / tf.reduce_sum(tf.pow(p, 1/T), axis=1, keepdims=True)\n",
        "\n",
        "\n",
        "def num_of_images(path):\n",
        "    image_datagen = ImageDataGenerator()\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        path,\n",
        "        classes = [\"mask\"],\n",
        "        class_mode = None)\n",
        "    return image_generator.samples\n",
        "\n",
        "def num_of_images2(path):\n",
        "    image_datagen = ImageDataGenerator()\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        path,\n",
        "        classes = [\"ul__val_images\"],\n",
        "        class_mode = None)\n",
        "    return image_generator.samples\n",
        "\n",
        "#mask name should end with '_gt' following the image name\n",
        "def validation(image_path,mask_path,image_prefix = \".png\",mask_prefix = \"_gt.png\"):\n",
        "    image_name_arr = glob.glob(os.path.join(image_path,\"*%s\"%image_prefix))\n",
        "\n",
        "    image_arr = []\n",
        "    mask_arr = []\n",
        "    for index,item in enumerate(image_name_arr):\n",
        "\n",
        "        img = cv2.cvtColor(cv2.imread(item),cv2.COLOR_BGR2RGB)\n",
        "        mask= cv2.cvtColor(cv2.imread(item.replace(image_path,mask_path).replace(image_prefix,mask_prefix)),cv2.COLOR_BGR2RGB)\n",
        "        img = img[:,:,:3]\n",
        "        mask = mask[:,:,:3] if mask.ndim==3 else np.repeat(mask[:,:,np.newaxis],3,axis=-1)\n",
        "        img,mask = adjustData(img,mask)\n",
        "        image_arr.append(img)\n",
        "        mask_arr.append(mask)\n",
        "    image_arr = np.array(image_arr)\n",
        "    mask_arr = np.array(mask_arr)\n",
        "    return image_arr,mask_arr, image_name_arr\n",
        "\n",
        "def validation2(image_path):\n",
        "    image_name_arr = glob.glob(os.path.join(image_path,\"*.png\"))\n",
        "    image_arr = []\n",
        "    for index,item in enumerate(image_name_arr):\n",
        "        img = cv2.cvtColor(cv2.imread(item),cv2.COLOR_BGR2RGB)\n",
        "        img = img[:,:,:3]\n",
        "        img = img/255\n",
        "        image_arr.append(img)\n",
        "    image_arr = np.array(image_arr)\n",
        "    return image_arr, image_name_arr\n",
        "    \n",
        "def weight(mask_path,mask_prefix = \"_gt.png\"):\n",
        "    image_name_arr = glob.glob(os.path.join(mask_path,\"*%s\"%mask_prefix))\n",
        "    no_images = len(image_name_arr)\n",
        "    class_1=0\n",
        "    class_2=0\n",
        "    class_3=0\n",
        "    class_0=0\n",
        "    tot = size*size*no_images\n",
        "    for index,item in enumerate(image_name_arr):\n",
        "        mask = cv2.cvtColor(cv2.imread(item),cv2.COLOR_BGR2RGB)\n",
        "        mask = mask[:,:,:3] \n",
        "        class_1 += np.sum(np.all(mask==class1,axis=-1))\n",
        "        class_2 += np.sum(np.all(mask==class2,axis=-1))\n",
        "        class_3 += np.sum(np.all(mask==class3,axis=-1))\n",
        "        class_0 += np.sum(np.all(mask==class0,axis=-1))\n",
        "    class1_wt = (tot - class_1)/tot\n",
        "    class2_wt = (tot - class_2)/tot\n",
        "    class3_wt = (tot - class_3)/tot\n",
        "    class0_wt = (tot - class_0)/tot\n",
        "    class_weight = [class1_wt,class2_wt,class3_wt,class0_wt]\n",
        "    return class_weight,no_images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICgFL5eu5ZoW"
      },
      "source": [
        "ss_utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CISanJdC5O3X"
      },
      "outputs": [],
      "source": [
        "import tensorflow_addons as tfa\n",
        "import tensorflow as tf\n",
        "from keras.layers import Layer\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.utils import shuffle\n",
        "import cv2\n",
        "\n",
        "def parameter_sampling(augm_per_image=10):\n",
        "    HORIZONTAL_FLIP_PROBALITIY=0.5\n",
        "    VERTICAL_FLIP_PROBALITIY=0.5\n",
        "    SHIFT_PROBALITIY=0.5\n",
        "    ROTATE_PROPBABILITY=0.5\n",
        "    ZOOM_PROPBABILITY=0.2\n",
        "    MAXIMUM_ROTATION_ANGLE=5\n",
        "    MAXIMUM_SHIFT=5\n",
        "    MINIMUM_ZOOM=0.8\n",
        "    MAXIMUM_ZOOM=1.2\n",
        "    \n",
        "    coin1 = np.less(np.random.uniform(0, 1.0,augm_per_image), ROTATE_PROPBABILITY) # for enabling rotation\n",
        "    coin2 = np.less(np.random.uniform(0, 1.0,2*augm_per_image), SHIFT_PROBALITIY) # for enabling shifting\n",
        "    coin2 = np.reshape(coin2,(augm_per_image,2)) # reshaping to 2 columns for height and width shift  \n",
        "    coin3 = np.less(np.random.uniform(0,1.0,(augm_per_image,)), ZOOM_PROPBABILITY)  # for enabling zoom  \n",
        "    h_flips = np.less(np.random.uniform(0, 1.0,augm_per_image), HORIZONTAL_FLIP_PROBALITIY) # An array of bolean values which tells horizontally flip or not.    \n",
        "    v_flips = np.less(np.random.uniform(0, 1.0,augm_per_image), VERTICAL_FLIP_PROBALITIY) # An array of bolean values which tells vertically flip or not.\n",
        "    shift = np.random.randint( 0, MAXIMUM_SHIFT, 2*augm_per_image) # An array of a pair of values for height and width shift\n",
        "    shift = np.reshape(shift,(augm_per_image,2)) # reshaping to 2 columns for height and width shift\n",
        "    shift *= coin2 # multiplying parameter with coin to enabling augmentation only when coin is True\n",
        "        \n",
        "    inv_shift = shift*-1    # inverse parameter for shifting\n",
        "    angle_rad = MAXIMUM_ROTATION_ANGLE * 3.141592653589793 / 180.0\n",
        "    angles = np.random.uniform(-angle_rad, angle_rad, augm_per_image) # angles in radian\n",
        "    inv_angle = angles*-1 # inverse parameter for rotation\n",
        "    scales = np.random.uniform(MINIMUM_ZOOM,MAXIMUM_ZOOM,(augm_per_image,)) # zoom in and out range\n",
        "    scales *= coin3 # multiplying parameter with coin to enabling augmentation only when coin is True\n",
        "    scales[(scales==0.0)] = 1.0 # No zoom is when scale is 1. so 0 is changed to 1.\n",
        "    \n",
        "    boxes = np.zeros((len(scales), 4)) # boxes for zoom is created with 4 parameters(x1,y1,x2,y2) the minimum and maximum cordinates\n",
        "    inv_boxes = np.zeros((len(scales), 4)) # inverse parameter for zoom\n",
        "    for i, scale in enumerate(scales):\n",
        "        x1 = y1 = 0.5 - (0.5 * scale) \n",
        "        x2 = y2 = 0.5 + (0.5 * scale)\n",
        "        boxes[i] = [x1, y1, x2, y2]\n",
        "        x3 = y3 = 0.5 - (0.5 / scale)\n",
        "        x4 = y4 = 0.5 + (0.5 / scale)\n",
        "        inv_boxes[i] = [x3, y3, x4, y4]\n",
        "    box_indices = np.arange(0,len(scales))\n",
        "    return h_flips,v_flips,angles,inv_angle,shift,inv_shift,boxes,box_indices,inv_boxes  #parameters for augmentation and reverse augmentation\n",
        "\n",
        "def proj_translations(translations):\n",
        "    num_translations = tf.shape(translations)[0]\n",
        "        # The translation matrix looks like:\n",
        "        #     [[1 0 -dx]\n",
        "        #      [0 1 -dy]\n",
        "        #      [0 0 1]]\n",
        "        # where the last entry is implicit.\n",
        "        # Translation matrices are always float32.\n",
        "    return tf.concat(\n",
        "            values=[\n",
        "                tf.ones((num_translations, 1), tf.float32),\n",
        "                tf.zeros((num_translations, 1), tf.float32),\n",
        "                -translations[:, 0, None],\n",
        "                tf.zeros((num_translations, 1), tf.float32),\n",
        "                tf.ones((num_translations, 1), tf.float32),\n",
        "                -translations[:, 1, None],\n",
        "                tf.zeros((num_translations, 2), tf.float32),\n",
        "            ],\n",
        "            axis=1,\n",
        "        )\n",
        "# classes for each type of augmentation\n",
        "\n",
        "class HorizontalFlip():     \n",
        "    def __init__(self, h_flips,**kwargs):\n",
        "        self.h_flips = h_flips\n",
        "       \n",
        "    def __call__(self, img, **kwargs):\n",
        "        batch_size = tf.shape(img)[0]\n",
        "        flip_size = tf.shape(self.h_flips)[0]  #gives the no. of augmentaion\n",
        "        flips = tf.reshape(self.h_flips, [flip_size, 1, 1, 1]) # making flips as the same dimension of image for broadcasting\n",
        "        flips = tf.cast(flips, img.dtype)\n",
        "        flipped_input = tf.reverse(img, [2]) # reversing the columns of the image\n",
        "        im = flips * flipped_input + (1 - flips) * img # To flip the image only when the parameter flips is True\n",
        "        return im\n",
        "\n",
        "class VerticalFlip():\n",
        "    def __init__(self, v_flips,**kwargs):\n",
        "        self.v_flips = v_flips\n",
        "        \n",
        "    def __call__(self, img, **kwargs):\n",
        "        batch_size = tf.shape(img)[0]\n",
        "        flip_size = tf.shape(self.v_flips)[0] #gives the no. of augmentaion\n",
        "        flips = tf.reshape(self.v_flips, [flip_size, 1, 1, 1])  # making flips as the same dimension of image for broadcasting\n",
        "        flips = tf.cast(flips, img.dtype)   \n",
        "        flipped_input = tf.reverse(img, [1]) # reversing the rows of the image\n",
        "        im = flips * flipped_input + (1 - flips) * img #To flip the image only when the parameter flips is True\n",
        "        return im\n",
        "\n",
        "class RandomRotate():\n",
        "    def __init__(self, angles,**kwargs):\n",
        "        self.angles = angles\n",
        "        \n",
        "    def __call__(self, img, **kwargs):\n",
        "        shp = tf.shape(img)\n",
        "        batch_size, height, width = shp[0], shp[1], shp[2]\n",
        "        f = tfa.image.transform_ops.angles_to_projective_transforms(self.angles, tf.cast(height, tf.float32), tf.cast(width, tf.float32))\n",
        "        img = tf.raw_ops.ImageProjectiveTransformV2(images=img, transforms=f, output_shape=[height,width], interpolation='NEAREST', fill_mode='REFLECT', name=None)\n",
        "        return img\n",
        "\n",
        "class Height_Width_Shift():\n",
        "    __name__ = \"Height_Width_Shift\" \n",
        "    def __init__(self, shift,**kwargs):\n",
        "        self.shift = shift\n",
        "        \n",
        "    def __call__(self, img, **kwargs):\n",
        "        shp = tf.shape(img)\n",
        "        batch_size, height, width = shp[0], shp[1], shp[2]\n",
        "        f = tfa.image.translate_ops.translations_to_projective_transforms(self.shift)\n",
        "        #f = proj_translations(self.shift)\n",
        "        img = tf.raw_ops.ImageProjectiveTransformV2(images=img, transforms=f, output_shape=[height,width], interpolation='NEAREST', fill_mode='REFLECT', name=None)\n",
        "        #img = tf.contrib.image.transform(images=img, transforms=f, interpolation='NEAREST')\n",
        "        return img\n",
        "\n",
        "class Crop_Resize():\n",
        "    def __init__(self, boxes,box_indices,**kwargs):\n",
        "        self.boxes = boxes\n",
        "        self.box_indices = box_indices\n",
        "        \n",
        "    def __call__(self, img, **kwargs):\n",
        "        shp = tf.shape(img)\n",
        "        batch_size, height, width = shp[0], shp[1], shp[2]\n",
        "        CROP_SIZE = (height, width)\n",
        "        img = tf.image.crop_and_resize(img, self.boxes, self.box_indices, CROP_SIZE) #\n",
        "        return img\n",
        "\n",
        "# function which perform all the augmntations\n",
        "def augment(inputs, transforms):\n",
        "    for t in transforms:\n",
        "        inputs = t(inputs)\n",
        "    return inputs\n",
        "\n",
        "\n",
        "def resize_if_needed(img, output_dim):\n",
        "    shp = tf.shape(img)\n",
        "    batch_size, height, width, channels = shp[0], shp[1], shp[2], shp[3]\n",
        "    if height != output_dim[0] or width != output_dim[1]:\n",
        "        size = tf.constant(output_dim[:2], dtype=tf.int32)\n",
        "        img = tf.image.resize(img, size=size)\n",
        "    return img\n",
        "\n",
        "\n",
        "# custom layer class for doing augmentation\n",
        "\n",
        "class AugmLayer(Layer):\n",
        "    def __init__(self, transforms, output_dim=None, preproc_input=None, **kwargs):\n",
        "        self.output_dim = output_dim\n",
        "        self.transforms = transforms\n",
        "        self.preproc_input = preproc_input\n",
        "        super(AugmLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(AugmLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, training=None, **kwargs):\n",
        "        ret = K.in_train_phase(augment(inputs, self.transforms), inputs, training=training)\n",
        "        if self.output_dim is not None:\n",
        "            ret = resize_if_needed(ret, self.output_dim)\n",
        "        if self.preproc_input is not None:\n",
        "            ret = self.preproc_input(ret)\n",
        "        return ret\n",
        "\n",
        "\n",
        "def transforms(m):\n",
        "    h_flips,v_flips,angles,inv_angle,shift,inv_shift,boxes,box_indices,inv_boxes = parameter_sampling(m) # created the parameters for augmentation of labelled images\n",
        "\n",
        "    transforms = [\n",
        "    HorizontalFlip(h_flips),\n",
        "    VerticalFlip(v_flips),\n",
        "    Height_Width_Shift(shift),\n",
        "    #RandomRotate(angles),\n",
        "    Crop_Resize(boxes,box_indices)\n",
        "    ] \n",
        "\n",
        "    inv_transforms = [              \n",
        "    Crop_Resize(inv_boxes,box_indices),\n",
        "    #RandomRotate(inv_angle),\n",
        "    Height_Width_Shift(inv_shift),\n",
        "    VerticalFlip(v_flips),\n",
        "    HorizontalFlip(h_flips)\n",
        "    ] \n",
        "    return transforms,inv_transforms  \n",
        "\n",
        "# Meric for finding fscore \n",
        "def fscore(y_true,y_pred):\n",
        "    y_true = y_true[:,:,:,:-1]\n",
        "    y_pred = y_pred[:,:,:,:-1]\n",
        "    y_true = K.round(K.flatten(y_true))\n",
        "    y_pred = K.round(K.flatten(y_pred)) \n",
        "    true_positives = K.sum(K.round(y_true * y_pred))\n",
        "    predicted_positives = K.sum(K.round(y_pred))\n",
        "    possible_positives = K.sum(K.round(y_true))\n",
        "    precision = true_positives / (predicted_positives+ K.epsilon())   \n",
        "    recall = true_positives / (possible_positives+ K.epsilon())  \n",
        "    f_score1 = 2*((precision*recall)/(precision+recall+ K.epsilon()))\n",
        "    return f_score1    \n",
        "  \n",
        " \n",
        "def fscore_benign(y_true,y_pred):\n",
        "    y_true1 = y_true[...,0]\n",
        "    y_pred1 = y_pred[...,0]\n",
        "    y_true1 = K.round(K.flatten(y_true1))\n",
        "    y_pred1 = K.round(K.flatten(y_pred1)) \n",
        "    true_positives1 = K.sum(y_true1 * y_pred1)\n",
        "    predicted_positives1 = K.sum(y_pred1)\n",
        "    possible_positives1 = K.sum(y_true1)\n",
        "    precision1 = true_positives1 / (predicted_positives1+ K.epsilon())   \n",
        "    recall1 = true_positives1 / (possible_positives1+ K.epsilon())  \n",
        "    f_score1 = 2*precision1*recall1/(precision1+recall1+ K.epsilon())\n",
        "    return f_score1  \n",
        "\n",
        "def fscore_mal(y_true,y_pred):\n",
        "    y_true2 = y_true[...,1]\n",
        "    y_pred2 = y_pred[...,1]\n",
        "    y_true2 = K.round(K.flatten(y_true2))\n",
        "    y_pred2 = K.round(K.flatten(y_pred2)) \n",
        "    true_positives2 = K.sum(y_true2 * y_pred2)\n",
        "    predicted_positives2 = K.sum(y_pred2)\n",
        "    possible_positives2 = K.sum(y_true2)\n",
        "    precision2 = true_positives2 / (predicted_positives2+ K.epsilon())   \n",
        "    recall2 = true_positives2 / (possible_positives2+ K.epsilon())  \n",
        "    f_score2 = 2*precision2*recall2/(precision2+recall2+ K.epsilon())\n",
        "    return f_score2  \n",
        "    \n",
        "# Custom loss function\n",
        "\n",
        "    \n",
        "def semi_loss(y_actual,y_predicted):\n",
        "    y_actual = y_actual[0]\n",
        "    y_actual = tf.reshape(y_actual,[k+l,size,size,num_classes])\n",
        "    cce = custom_ce(y_actual[0],y_predicted[0])\n",
        "    mse = custom_mse(y_actual[1:],y_predicted[1:])    \n",
        "    #cce = custom_ce(y_actual[0],y_predicted[0,64:-64,64:-64,:])\n",
        "    #mse = custom_mse(y_actual[1:],y_predicted[1:,64:-64,64:-64,:])\n",
        "    loss_value = cce + lambda_u * mse  \n",
        "    return loss_value    \n",
        "\n",
        "def custom_ce(y_actual,y_predicted):\n",
        "    loss_value1 = -K.mean(K.sum( y_actual * K.log( y_predicted + K.epsilon()),axis=-1))\n",
        "    return loss_value1 \n",
        "\n",
        "def custom_ce1(y_actual,y_predicted):\n",
        "    loss_value1 = -(K.sum(y_actual * K.log( y_predicted + K.epsilon()),axis=-1))\n",
        "    return loss_value1 \n",
        "             \n",
        "def custom_mse(y_actual,y_predicted):\n",
        "    loss_value2 = K.mean(K.mean( K.square(y_actual-y_predicted),axis=-1))\n",
        "    return loss_value2\n",
        "\n",
        "def colour_code(image, label_values):\n",
        "    x = np.argmax(image, axis = -1)\n",
        "    colour_codes = np.array(label_values)\n",
        "    x = colour_codes[x.astype(int)]\n",
        "    return x\n",
        "    \n",
        "def shuffling(x, y):\n",
        "    x, y = shuffle(x, y, random_state=42)\n",
        "    return x, y\n",
        "\n",
        "def shuffling2(x):\n",
        "    x = shuffle(x)\n",
        "    return x\n",
        "    \n",
        "def one_hot(mask):\n",
        "    semantic_map = []\n",
        "    for colour in label_values:\n",
        "        equality = np.equal(mask, colour)\n",
        "        class_map = np.all(equality, axis = -1)\n",
        "        semantic_map.append(class_map)\n",
        "    semantic_map = (np.stack(semantic_map, axis=-1)).astype(float)\n",
        "    return semantic_map\n",
        "\n",
        "def read_image(x):\n",
        "    x = x.decode()\n",
        "    image = cv2.imread(x, cv2.IMREAD_COLOR)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = image/255.0\n",
        "    image = image.astype(np.float32)\n",
        "    return image\n",
        "\n",
        "def read_mask(y):\n",
        "    y = y.decode()\n",
        "    mask = cv2.imread(y, cv2.IMREAD_COLOR)\n",
        "    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
        "    mask = one_hot(mask)\n",
        "    mask = mask.astype(np.float32)\n",
        "    return mask\n",
        "\n",
        "\n",
        "def loss_ul(y_actual,y_predicted):\n",
        "    y_actual = tf.where(y_actual > 0.5, x = 1., y=0., name=None)\n",
        "    y_actual = tf.cast(y_actual, dtype=tf.float32, name=None)\n",
        "    cce = custom_ce1(y_actual,y_predicted)\n",
        "    cce = cce[cce>0.]\n",
        "    cce = tf.concat([cce,[0.0]],axis=-1)\n",
        "    loss = K.mean(cce)\n",
        "    return loss\n",
        "\n",
        "cce_loss = tf.keras.losses.CategoricalCrossentropy()    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrnD3VN26Q3Q"
      },
      "source": [
        "m_resunet.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMdjSg4x6Qe1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def squeeze_excite_block(inputs, ratio=8):\n",
        "    init = inputs\n",
        "    channel_axis = -1\n",
        "    filters = init.shape[channel_axis]\n",
        "    se_shape = (1, 1, filters)\n",
        "\n",
        "    se = GlobalAveragePooling2D()(init)\n",
        "    se = Reshape(se_shape)(se)\n",
        "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "\n",
        "    x = Multiply()([init, se])\n",
        "    return x\n",
        "\n",
        "def stem_block(x, n_filter, strides):\n",
        "    x_init = x\n",
        "\n",
        "    ## Conv 1\n",
        "    x = Conv2D(n_filter, (3, 3), padding=\"same\", strides=strides)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv2D(n_filter, (3, 3), padding=\"same\")(x)\n",
        "\n",
        "    ## Shortcut\n",
        "    s  = Conv2D(n_filter, (1, 1), padding=\"same\", strides=strides)(x_init)\n",
        "    s = BatchNormalization()(s)\n",
        "\n",
        "    ## Add\n",
        "    x = Add()([x, s])\n",
        "    x = squeeze_excite_block(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def resnet_block(x, n_filter, strides=1):\n",
        "    x_init = x\n",
        "\n",
        "    ## Conv 1\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv2D(n_filter, (3, 3), padding=\"same\", strides=strides)(x)\n",
        "    ## Conv 2\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv2D(n_filter, (3, 3), padding=\"same\", strides=1)(x)\n",
        "\n",
        "    ## Shortcut\n",
        "    s  = Conv2D(n_filter, (1, 1), padding=\"same\", strides=strides)(x_init)\n",
        "    s = BatchNormalization()(s)\n",
        "\n",
        "    ## Add\n",
        "    x = Add()([x, s])\n",
        "    x = squeeze_excite_block(x)\n",
        "    return x\n",
        "\n",
        "def aspp_block(x, num_filters, rate_scale=1):\n",
        "    x1 = Conv2D(num_filters, (3, 3), dilation_rate=(6 * rate_scale, 6 * rate_scale), padding=\"same\")(x)\n",
        "    x1 = BatchNormalization()(x1)\n",
        "\n",
        "    x2 = Conv2D(num_filters, (3, 3), dilation_rate=(12 * rate_scale, 12 * rate_scale), padding=\"same\")(x)\n",
        "    x2 = BatchNormalization()(x2)\n",
        "\n",
        "    x3 = Conv2D(num_filters, (3, 3), dilation_rate=(18 * rate_scale, 18 * rate_scale), padding=\"same\")(x)\n",
        "    x3 = BatchNormalization()(x3)\n",
        "\n",
        "    x4 = Conv2D(num_filters, (3, 3), padding=\"same\")(x)\n",
        "    x4 = BatchNormalization()(x4)\n",
        "\n",
        "    y = Add()([x1, x2, x3, x4])\n",
        "    y = Conv2D(num_filters, (1, 1), padding=\"same\")(y)\n",
        "    return y\n",
        "\n",
        "def attetion_block(g, x):\n",
        "    \"\"\"\n",
        "        g: Output of Parallel Encoder block\n",
        "        x: Output of Previous Decoder block\n",
        "    \"\"\"\n",
        "\n",
        "    filters = x.shape[-1]\n",
        "\n",
        "    g_conv = BatchNormalization()(g)\n",
        "    g_conv = Activation(\"relu\")(g_conv)\n",
        "    g_conv = Conv2D(filters, (3, 3), padding=\"same\")(g_conv)\n",
        "\n",
        "    g_pool = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(g_conv)\n",
        "\n",
        "    x_conv = BatchNormalization()(x)\n",
        "    x_conv = Activation(\"relu\")(x_conv)\n",
        "    x_conv = Conv2D(filters, (3, 3), padding=\"same\")(x_conv)\n",
        "\n",
        "    gc_sum = Add()([g_pool, x_conv])\n",
        "\n",
        "    gc_conv = BatchNormalization()(gc_sum)\n",
        "    gc_conv = Activation(\"relu\")(gc_conv)\n",
        "    gc_conv = Conv2D(filters, (3, 3), padding=\"same\")(gc_conv)\n",
        "\n",
        "    gc_mul = Multiply()([gc_conv, x])\n",
        "    return gc_mul\n",
        "\n",
        "class ResUnetPlusPlus:\n",
        "    def __init__(self, input_size=512, no_classes=4):\n",
        "        self.input_size = input_size\n",
        "        self.classes = no_classes\n",
        "\n",
        "    def build_model(self):\n",
        "        n_filters = [16, 32, 64, 128, 256]\n",
        "        inputs = Input((self.input_size, self.input_size, 3))\n",
        "\n",
        "        c0 = inputs\n",
        "        c1 = stem_block(c0, n_filters[0], strides=1)\n",
        "\n",
        "        ## Encoder\n",
        "        c2 = resnet_block(c1, n_filters[1], strides=2)\n",
        "        c3 = resnet_block(c2, n_filters[2], strides=2)\n",
        "        c4 = resnet_block(c3, n_filters[3], strides=2)\n",
        "\n",
        "        ## Bridge\n",
        "        b1 = aspp_block(c4, n_filters[4])\n",
        "\n",
        "        ## Decoder\n",
        "        d1 = attetion_block(c3, b1)\n",
        "        d1 = UpSampling2D((2, 2))(d1)\n",
        "        d1 = Concatenate()([d1, c3])\n",
        "        d1 = resnet_block(d1, n_filters[3])\n",
        "\n",
        "        d2 = attetion_block(c2, d1)\n",
        "        d2 = UpSampling2D((2, 2))(d2)\n",
        "        d2 = Concatenate()([d2, c2])\n",
        "        d2 = resnet_block(d2, n_filters[2])\n",
        "\n",
        "        d3 = attetion_block(c1, d2)\n",
        "        d3 = UpSampling2D((2, 2))(d3)\n",
        "        d3 = Concatenate()([d3, c1])\n",
        "        d3 = resnet_block(d3, n_filters[1])\n",
        "\n",
        "        ## output\n",
        "        outputs = aspp_block(d3, n_filters[0])\n",
        "        outputs = Conv2D(self.classes, (1, 1), padding=\"same\")(outputs)\n",
        "        outputs = Activation(\"softmax\")(outputs)\n",
        "\n",
        "        ## Model\n",
        "        model = Model(inputs, outputs)\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2QzRtLrVUqI",
        "outputId": "61fde673-2c6c-46fe-8498-cff3dc5cf084"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"base_model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 512, 512, 16  448         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 512, 512, 16  64         ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 512, 512, 16  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 512, 512, 16  64          ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 512, 512, 16  2320        ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 512, 512, 16  64         ['conv2d_2[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 512, 512, 16  0           ['conv2d_1[0][0]',               \n",
            "                                )                                 'batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 16)          0           ['add[0][0]']                    \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 1, 1, 16)     0           ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1, 1, 2)      32          ['reshape[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1, 1, 16)     32          ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 512, 512, 16  0           ['add[0][0]',                    \n",
            "                                )                                 'dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 512, 512, 16  64         ['multiply[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 512, 512, 16  0           ['batch_normalization_2[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 256, 256, 32  4640        ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 256, 256, 32  128        ['conv2d_3[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 256, 256, 32  0           ['batch_normalization_3[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 256, 256, 32  544         ['multiply[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 256, 256, 32  9248        ['activation_2[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 256, 256, 32  128        ['conv2d_5[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 256, 256, 32  0           ['conv2d_4[0][0]',               \n",
            "                                )                                 'batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1 (Gl  (None, 32)          0           ['add_1[0][0]']                  \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 1, 1, 32)     0           ['global_average_pooling2d_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 1, 1, 4)      128         ['reshape_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 1, 1, 32)     128         ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 256, 256, 32  0           ['add_1[0][0]',                  \n",
            "                                )                                 'dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 256, 256, 32  128        ['multiply_1[0][0]']             \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 256, 256, 32  0           ['batch_normalization_5[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 128, 128, 64  18496       ['activation_3[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 128, 128, 64  256        ['conv2d_6[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 128, 128, 64  0           ['batch_normalization_6[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 128, 128, 64  2112        ['multiply_1[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 128, 128, 64  36928       ['activation_4[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 128, 128, 64  256        ['conv2d_8[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 128, 128, 64  0           ['conv2d_7[0][0]',               \n",
            "                                )                                 'batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2 (Gl  (None, 64)          0           ['add_2[0][0]']                  \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)            (None, 1, 1, 64)     0           ['global_average_pooling2d_2[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 1, 1, 8)      512         ['reshape_2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 1, 1, 64)     512         ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 128, 128, 64  0           ['add_2[0][0]',                  \n",
            "                                )                                 'dense_5[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 128, 128, 64  256        ['multiply_2[0][0]']             \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 128, 128, 64  0           ['batch_normalization_8[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 64, 64, 128)  73856       ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 64, 64, 128)  512        ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 64, 64, 128)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 64, 64, 128)  8320        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 64, 64, 128)  147584      ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 64, 64, 128)  512        ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 64, 64, 128)  0           ['conv2d_10[0][0]',              \n",
            "                                                                  'batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " global_average_pooling2d_3 (Gl  (None, 128)         0           ['add_3[0][0]']                  \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " reshape_3 (Reshape)            (None, 1, 1, 128)    0           ['global_average_pooling2d_3[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 1, 1, 16)     2048        ['reshape_3[0][0]']              \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 1, 1, 128)    2048        ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 64, 64, 128)  0           ['add_3[0][0]',                  \n",
            "                                                                  'dense_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 64, 64, 256)  295168      ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 64, 64, 256)  295168      ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 64, 64, 256)  295168      ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 64, 64, 256)  295168      ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 64, 64, 256)  0           ['batch_normalization_11[0][0]', \n",
            "                                                                  'batch_normalization_12[0][0]', \n",
            "                                                                  'batch_normalization_13[0][0]', \n",
            "                                                                  'batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 128, 128, 64  256        ['multiply_2[0][0]']             \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 64, 64, 256)  65792       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 128, 128, 64  0           ['batch_normalization_15[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 128, 128, 25  147712      ['activation_7[0][0]']           \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 64, 64, 256)  0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 64, 64, 256)  0           ['max_pooling2d[0][0]',          \n",
            "                                                                  'conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 64, 64, 256)  1024       ['add_5[0][0]']                  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 64, 64, 256)  0           ['conv2d_19[0][0]',              \n",
            "                                                                  'conv2d_16[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2D)   (None, 128, 128, 25  0           ['multiply_4[0][0]']             \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 128, 128, 32  0           ['up_sampling2d[0][0]',          \n",
            "                                0)                                'multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 128, 128, 32  1280       ['concatenate[0][0]']            \n",
            " ormalization)                  0)                                                                \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_18[0][0]'] \n",
            "                                0)                                                                \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 128, 128, 12  368768      ['activation_10[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 128, 128, 12  512        ['conv2d_20[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_19[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 128, 128, 12  41088       ['concatenate[0][0]']            \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 128, 128, 12  147584      ['activation_11[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 128, 128, 12  512        ['conv2d_22[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 128, 128, 12  0           ['conv2d_21[0][0]',              \n",
            "                                8)                                'batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " global_average_pooling2d_4 (Gl  (None, 128)         0           ['add_6[0][0]']                  \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " reshape_4 (Reshape)            (None, 1, 1, 128)    0           ['global_average_pooling2d_4[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 1, 1, 16)     2048        ['reshape_4[0][0]']              \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 1, 1, 128)    2048        ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 256, 256, 32  128        ['multiply_1[0][0]']             \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 128, 128, 12  0           ['add_6[0][0]',                  \n",
            "                                8)                                'dense_9[0][0]']                \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 256, 256, 32  0           ['batch_normalization_21[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 128, 128, 12  512        ['multiply_5[0][0]']             \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 256, 256, 12  36992       ['activation_12[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_22[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 12  0          ['conv2d_23[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 128, 128, 12  147584      ['activation_13[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 128, 128, 12  0           ['max_pooling2d_1[0][0]',        \n",
            "                                8)                                'conv2d_24[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 128, 128, 12  512        ['add_7[0][0]']                  \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_23[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 128, 128, 12  147584      ['activation_14[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 128, 128, 12  0           ['conv2d_25[0][0]',              \n",
            "                                8)                                'multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSampling2D)  (None, 256, 256, 12  0          ['multiply_6[0][0]']             \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 256, 256, 16  0           ['up_sampling2d_1[0][0]',        \n",
            "                                0)                                'multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 256, 256, 16  640        ['concatenate_1[0][0]']          \n",
            " ormalization)                  0)                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 256, 256, 16  0           ['batch_normalization_24[0][0]'] \n",
            "                                0)                                                                \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 256, 256, 64  92224       ['activation_15[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 256, 256, 64  256        ['conv2d_26[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_25[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 256, 256, 64  10304       ['concatenate_1[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 256, 256, 64  36928       ['activation_16[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 256, 256, 64  256        ['conv2d_28[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 256, 256, 64  0           ['conv2d_27[0][0]',              \n",
            "                                )                                 'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " global_average_pooling2d_5 (Gl  (None, 64)          0           ['add_8[0][0]']                  \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " reshape_5 (Reshape)            (None, 1, 1, 64)     0           ['global_average_pooling2d_5[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 1, 1, 8)      512         ['reshape_5[0][0]']              \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 1, 1, 64)     512         ['dense_10[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 512, 512, 16  64         ['multiply[0][0]']               \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 256, 256, 64  0           ['add_8[0][0]',                  \n",
            "                                )                                 'dense_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 512, 512, 16  0           ['batch_normalization_27[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 256, 256, 64  256        ['multiply_7[0][0]']             \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 512, 512, 64  9280        ['activation_17[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_28[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 256, 256, 64  0          ['conv2d_29[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 256, 256, 64  36928       ['activation_18[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 256, 256, 64  0           ['max_pooling2d_2[0][0]',        \n",
            "                                )                                 'conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 256, 256, 64  256        ['add_9[0][0]']                  \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_29[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 256, 256, 64  36928       ['activation_19[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 256, 256, 64  0           ['conv2d_31[0][0]',              \n",
            "                                )                                 'multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSampling2D)  (None, 512, 512, 64  0          ['multiply_8[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 512, 512, 80  0           ['up_sampling2d_2[0][0]',        \n",
            "                                )                                 'multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 512, 512, 80  320        ['concatenate_2[0][0]']          \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 512, 512, 80  0           ['batch_normalization_30[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 512, 512, 32  23072       ['activation_20[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 512, 512, 32  128        ['conv2d_32[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 512, 512, 32  0           ['batch_normalization_31[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 512, 512, 32  2592        ['concatenate_2[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 512, 512, 32  9248        ['activation_21[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 512, 512, 32  128        ['conv2d_34[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 512, 512, 32  0           ['conv2d_33[0][0]',              \n",
            "                                )                                 'batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " global_average_pooling2d_6 (Gl  (None, 32)          0           ['add_10[0][0]']                 \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " reshape_6 (Reshape)            (None, 1, 1, 32)     0           ['global_average_pooling2d_6[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 1, 1, 4)      128         ['reshape_6[0][0]']              \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 1, 1, 32)     128         ['dense_12[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 512, 512, 32  0           ['add_10[0][0]',                 \n",
            "                                )                                 'dense_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 512, 512, 16  4624        ['multiply_9[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 512, 512, 16  4624        ['multiply_9[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 512, 512, 16  4624        ['multiply_9[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 512, 512, 16  4624        ['multiply_9[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 512, 512, 16  64         ['conv2d_35[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 512, 512, 16  64         ['conv2d_36[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 512, 512, 16  64         ['conv2d_37[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 512, 512, 16  64         ['conv2d_38[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 512, 512, 16  0           ['batch_normalization_33[0][0]', \n",
            "                                )                                 'batch_normalization_34[0][0]', \n",
            "                                                                  'batch_normalization_35[0][0]', \n",
            "                                                                  'batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 512, 512, 16  272         ['add_11[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 512, 512, 4)  68          ['conv2d_39[0][0]']              \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 512, 512, 4)  0           ['conv2d_40[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,070,436\n",
            "Trainable params: 4,063,044\n",
            "Non-trainable params: 7,392\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 12/12\n",
            "836/836 [==============================] - 1020s 1s/step - loss: 0.4087 - accuracy: 0.8768 - fscore: 0.4490 - val_loss: 0.4686 - val_accuracy: 0.8501 - val_fscore: 0.2422\n",
            "time taken for training 1 is 1043.2329816818237 seconds\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "from tensorflow.keras.metrics import *\n",
        "from tensorflow.keras import layers\n",
        "# from m_resunet import ResUnetPlusPlus\n",
        "import tensorflow_addons as tfa\n",
        "from keras.models import load_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Concatenate, Cropping2D\n",
        "from keras.layers import Input,Layer,Lambda, AveragePooling2D, Activation, Concatenate, Cropping2D\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "from keras import optimizers\n",
        "import sys,math,csv,time\n",
        "from pathlib import Path\n",
        "from sklearn.utils import shuffle\n",
        "import glob\n",
        "# import ss_utils\n",
        "# from ss_utils import *\n",
        "#K.set_floatx('float64')\n",
        "\n",
        "\n",
        "#cce = tf.keras.losses.categorical_crossentropy()\n",
        "cce=tf.keras.losses.CategoricalCrossentropy()\n",
        "loss_fn = cce\n",
        "class1 = [0,160,255] #blue\n",
        "class2 = [255,255,128] #yellow\n",
        "class3 = [255,0,0] #red\n",
        "class0 = [0,0,0] #background which is the final class\n",
        "\n",
        "label_values = [class1] + [class2] + [class3] + [class0]\n",
        "num_classes = len(label_values)\n",
        "\n",
        "  \n",
        "csv_name = \"/content/drive/MyDrive/KMC/ResUnet++/CSV/training.csv\"\n",
        "csv_name2 = \"/content/drive/MyDrive/KMC/ResUnet++/CSV/validation.csv\"\n",
        "\n",
        "\n",
        "train_path = \"/content/drive/MyDrive/KMC/ResUnet++/Data_keras/10x/train_384/\"\n",
        "valid_path = \"/content/drive/MyDrive/KMC/ResUnet++/Data_keras/10x/val_384/\"\n",
        "\n",
        "weights_folder= \"/content/drive/MyDrive/KMC/ResUnet++/weight_sct/10x/weights_resunet11\"\n",
        "\n",
        "if os.path.isdir(weights_folder) is not True:\n",
        "    os.mkdir(weights_folder)\n",
        "\n",
        "model_name = \"/content/drive/MyDrive/KMC/ResUnet++/modelh5/core_model.h5\" \n",
        "## Training\n",
        "\n",
        "train_xl = sorted(glob.glob(os.path.join(train_path, \"images\", \"*.png\")))   \n",
        "train_yl = sorted(glob.glob(os.path.join(train_path, \"mask\", \"*.png\")))\n",
        "\n",
        "## Shuffling\n",
        "train_xl, train_yl = shuffling(train_xl, train_yl)\n",
        "\n",
        "\n",
        "## Validation\n",
        "valid_xl = sorted(glob.glob(os.path.join(valid_path, \"images\", \"*.png\")))\n",
        "valid_yl = sorted(glob.glob(os.path.join(valid_path, \"mask\", \"*.png\")))\n",
        "\n",
        "final_epoch = 12\n",
        "lr = 1e-6\n",
        "batch_size = 1 # No. of images in  training and validation batch\n",
        "size =512\n",
        "# weights_10x = [0.967,0.96,0.88,0.974,0.219]\n",
        "rms = keras.optimizers.RMSprop(lr=1e-6)\n",
        "opt = rms\n",
        "\n",
        "checkpoint_path = model_name\n",
        "# checkpoint_path = None\n",
        "if checkpoint_path is not None:\n",
        "   model = load_model(checkpoint_path, custom_objects={'fscore': fscore})\n",
        "   model.load_weights(\"%s/weights.010.hdf5\"%str(weights_folder)) # To continue from a particular epoch\n",
        "   i_epoch = 11\n",
        "else:\n",
        "  arch = ResUnetPlusPlus(input_size=size,no_classes=4)\n",
        "  model = arch.build_model()\n",
        "  model._name=\"base_model\"    \n",
        "  i_epoch = 0\n",
        "\n",
        "\n",
        "  \n",
        "print(model.summary())\n",
        "metrics = [\n",
        "    fscore,\n",
        "    fscore_benign,\n",
        "    fscore_mal\n",
        "   \n",
        "    ]\n",
        "\n",
        "\n",
        "num_train = len(train_xl)\n",
        "num_valid = len(valid_xl)\n",
        "train_steps = (num_train//batch_size)\n",
        "valid_steps = (num_valid//batch_size)\n",
        "\n",
        "# print(train_steps)\n",
        "# print(valid_steps)\n",
        "\n",
        "\n",
        "\n",
        "def data_aug(image,seed1):\n",
        "    data_augmentation = tf.keras.Sequential([\n",
        "  layers.RandomFlip(\"horizontal\",seed=seed1),\n",
        "  # layers.RandomRotation(0.09, interpolation='nearest',seed=seed1),\n",
        "  layers.RandomTranslation(height_factor=0.01, width_factor=0.01, fill_mode='reflect', interpolation='nearest', seed=seed1, fill_value=0.0),\n",
        "  layers.RandomZoom(height_factor=(-0.1,0.1), width_factor=None, fill_mode='reflect',\n",
        "    interpolation='nearest', seed=seed1, fill_value=0.0)])\n",
        "    return data_augmentation(image)\n",
        "    \n",
        "    \n",
        "def parse_data(x, y):\n",
        "    def _parse(x, y):\n",
        "        seed1 = tf.random.uniform(shape=[],minval=0,maxval=2048)\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y)\n",
        "        x = data_aug(x,seed1)\n",
        "        y = data_aug(y,seed1)\n",
        "        return x, y\n",
        "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n",
        "    x.set_shape([size, size, 3])\n",
        "    y.set_shape([size, size, num_classes])\n",
        "    return x, y\n",
        "\n",
        "\n",
        "def tf_dataset(x, y, batch=1):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "    #dataset = dataset.shuffle(buffer_size=32)\n",
        "    dataset = dataset.map(map_func=parse_data)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.batch(batch)\n",
        "    return dataset\n",
        " \n",
        "\n",
        "\n",
        "train_dataset = tf_dataset(train_xl, train_yl, batch=batch_size)  \n",
        "valid_dataset = tf_dataset(valid_xl, valid_yl, batch=batch_size) \n",
        "\n",
        "\n",
        "\n",
        "callbacks = [\n",
        "        ModelCheckpoint(filepath='%s/weights.{epoch:03d}.hdf5'%weights_folder,save_weights_only= True),\n",
        "        CSVLogger(csv_name,append=True)\n",
        "    ] \n",
        "    \n",
        "start = time.time()\n",
        "model.compile(optimizer = opt, loss = loss_fn, metrics =['accuracy',fscore], run_eagerly=True )\n",
        "model.fit(train_dataset,\n",
        "            epochs=final_epoch,\n",
        "            validation_data=valid_dataset,\n",
        "            steps_per_epoch=train_steps,\n",
        "            validation_steps=valid_steps,\n",
        "            callbacks=callbacks,\n",
        "            shuffle=False,\n",
        "            verbose=1,\n",
        "            initial_epoch = i_epoch)\n",
        "model.save(str(model_name))\n",
        "end = time.time()\n",
        "print(f\"time taken for training {final_epoch - i_epoch} is {end - start} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "bbONUxGaeJka",
        "outputId": "f4633bbe-b021-4906-9f08-bd7db0bccfa5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "from tensorflow.keras.metrics import *\n",
        "from tensorflow.keras import layers\n",
        "# from m_resunet import ResUnetPlusPlus\n",
        "import tensorflow_addons as tfa\n",
        "from keras.models import load_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Concatenate, Cropping2D\n",
        "from keras.layers import Input,Layer,Lambda, AveragePooling2D, Activation, Concatenate, Cropping2D\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "from keras import optimizers\n",
        "import sys,math,csv,time\n",
        "from pathlib import Path\n",
        "from sklearn.utils import shuffle\n",
        "import glob\n",
        "\n",
        "model = load_model(\"/content/drive/MyDrive/KMC/ResUnet++/modelh5/core_model.h5\", custom_objects={'fscore': fscore})\n",
        "model.load_weights(\"%s/weights.012.hdf5\" % str(weights_folder)) \n",
        "\n",
        "def colour_code(image, label_values):\n",
        "    x = np.argmax(image, axis = -1)\n",
        "    colour_codes = np.array(label_values)\n",
        "    x = colour_codes[x.astype(int)]\n",
        "    return x\n",
        "what = model.predict(valid_dataset,steps=5)\n",
        "\n",
        "z = colour_code(what,label_values)\n",
        "# for i in range(len(z)):\n",
        "#     a = img_name[i]\n",
        "#     image_name = os.path.basename(a)\n",
        "#     print(image_name)\n",
        "#     out = z[i]\n",
        "#     inp = val_y[i]\n",
        "#     image_name = image_name[:image_name.index('.')] \n",
        "#     save_img('%s/%s_pred.png'%(output_folder,image_name), out)\n",
        "#     save_img('%s/%s_%s.png'%(output_folder,image_name,img_type), inp)\n",
        "# end = time.time()\n",
        "\n",
        "# plt.imshow(valid_xl[0])\n",
        "# import sys # to access the system\n",
        "# import cv2\n",
        "# img = cv2.imread(\"\", cv2.IMREAD_ANYCOLOR)\n",
        "# print(f\"time taken for { len(z) } images is {end - start} seconds \")\n",
        "\n",
        "plt.imshow(z[0])\n",
        "plt.show()\n",
        "\n",
        "# what = model.predict(val_x)\n",
        "# print(z[0])\n",
        "# save_img(\"abc.png\", z[0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ResUnet_KMC.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}